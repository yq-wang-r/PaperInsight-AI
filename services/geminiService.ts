
import { GoogleGenAI, Tool, GenerateContentResponse } from "@google/genai";
import { AnalysisResult, ChatMessage, HistoryItem, TimelinessReport, IntegrityReport, VenueReport, UserSettings, ApiProvider } from "../types";

// --- Global Settings Store ---
// Default to Gemini (Environment variables will be used if user settings are empty)
let currentSettings: UserSettings = {
    provider: 'gemini',
    apiKey: '',
    baseUrl: '',
    model: 'gemini-2.0-flash', // Default fallback
    enableSearch: true
};

export const updateGlobalSettings = (settings: UserSettings) => {
    currentSettings = settings;
};

export const getGlobalSettings = () => currentSettings;

// --- Helper: Retry Logic ---

const wait = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function runWithRetry<T>(
    operation: () => Promise<T>, 
    signal?: AbortSignal,
    retries = 2, 
    baseDelay = 1000
): Promise<T> {
    try {
        if (signal?.aborted) throw new Error("Aborted");
        return await operation();
    } catch (error: any) {
        if (signal?.aborted) throw new Error("Aborted");

        const msg = error.message || "";
        // Retry on Server Errors (5xx) or specific Network errors
        const isServerErr = 
            error.status >= 500 || 
            msg.includes("500") || 
            msg.includes("503") ||
            msg.includes("Rpc failed") || 
            msg.includes("xhr error") ||
            msg.includes("fetch failed") ||
            msg.includes("Overloaded");

        // Do NOT retry on 30011 (Payment required) or 4xx errors
        if (msg.includes("30011") || msg.includes("401") || msg.includes("403")) {
            throw error;
        }

        if (isServerErr && retries > 0) {
            console.warn(`Transient Error (${retries} retries left):`, msg);
            await wait(baseDelay);
            return runWithRetry(operation, signal, retries - 1, baseDelay * 2);
        }
        throw error;
    }
}

// --- OpenAI / Zhipu Compatible Handler ---

async function callOpenAICompatible(
    prompt: string, 
    systemInstruction: string,
    isJsonMode: boolean = false,
    settings: UserSettings,
    signal?: AbortSignal
): Promise<{ text: string, sources?: any[] }> {
    const { apiKey, baseUrl, model, provider } = settings;
    
    // STRICT URL Logic: Ensure it ends with /chat/completions
    // SiliconFlow Example: https://api.siliconflow.cn/v1/chat/completions
    let url = baseUrl.replace(/\/+$/, ''); // Remove trailing slash
    if (!url.endsWith('/chat/completions')) {
         url = `${url}/chat/completions`;
    }

    // Special handling for Zhipu Web Search (Only for Zhipu)
    const tools = (provider === 'zhipu' && settings.enableSearch) 
        ? [{ type: "web_search", web_search: { enable: true, search_result: true } }] 
        : undefined;

    const messages = [
        { role: "system", content: systemInstruction },
        { role: "user", content: prompt }
    ];

    // Payload aligned strictly with standard Chat Completions API (and user's curl example)
    const body: any = {
        model: model,
        messages: messages,
        temperature: 0.7, // As requested in curl example
        max_tokens: 4096, // Using 4096 to ensure full paper analysis fits (User curl example used 1000, but app needs more)
        stream: false,
    };

    if (tools) body.tools = tools;
    
    // --- DEBUG LOGGING ---
    console.log(`%c[${provider.toUpperCase()} Request]`, "color: blue; font-weight: bold;");
    console.log("URL:", url);
    console.log("Model:", model);
    console.log("Payload:", JSON.stringify(body, null, 2));
    // ---------------------

    const response = await fetch(url, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify(body),
        signal
    });

    // --- DEBUG LOGGING ---
    console.log(`%c[${provider.toUpperCase()} Response Status]`, "color: green; font-weight: bold;", response.status);
    // ---------------------

    if (!response.ok) {
        const errText = await response.text();
        console.error("API Error Body:", errText); // Log raw error for user debugging

        let friendlyMessage = `Provider Error (${response.status})`;

        try {
            const errJson = JSON.parse(errText);
            const code = errJson.code || errJson.error?.code;
            const msg = errJson.message || errJson.error?.message || errText;

            // Handle SiliconFlow specific 30011 error
            if (code === 30011 || msg.includes("30011")) {
                friendlyMessage = `SiliconFlow Error (30011): This model (${model}) requires a paid balance. Please check your SiliconFlow dashboard to ensure your API Key is associated with a funded project/team. Try switching to a free model like 'deepseek-ai/DeepSeek-V3' or 'Qwen/Qwen2.5-72B-Instruct' if needed.`;
            } else {
                friendlyMessage = `Provider Error (${code}): ${msg}`;
            }
        } catch (e) {
            friendlyMessage += `: ${errText}`;
        }
        
        throw new Error(friendlyMessage);
    }

    const data = await response.json();
    console.log("Response Data:", data); // Log success data

    const content = data.choices?.[0]?.message?.content || "";
    
    // Attempt to extract Zhipu search results if available (structure varies, but usually in tool_calls or appended text)
    return { text: content, sources: [] }; 
}

// --- Gemini Handler (Existing Logic with Refinements) ---

async function callGemini(
    prompt: string,
    systemInstruction: string,
    isJsonMode: boolean,
    settings: UserSettings,
    signal?: AbortSignal,
    forceModel?: string // Allow overriding model for fallback chain
): Promise<{ text: string, sources?: any[] }> {
    // Priority: Settings Key > Env Key
    const finalKey = settings.apiKey || process.env.API_KEY;
    if (!finalKey) throw new Error("API Key is missing for Gemini.");

    const ai = new GoogleGenAI({ apiKey: finalKey });
    
    // Determine Model
    const modelToUse = forceModel || settings.model || 'gemini-2.0-flash';
    
    const config: any = {
        systemInstruction: systemInstruction,
        temperature: 0.3,
    };

    if (settings.enableSearch) {
        config.tools = [{ googleSearch: {} }];
    }
    
    if (isJsonMode) {
        config.responseMimeType = "application/json";
    }

    const response = await ai.models.generateContent({
        model: modelToUse,
        contents: prompt,
        config: config
    });

    return {
        text: response.text || "",
        sources: response.candidates?.[0]?.groundingMetadata?.groundingChunks || []
    };
}

// --- Unified Dispatcher ---

async function dispatchAIRequest(
    prompt: string,
    systemInstruction: string,
    isJsonMode: boolean,
    signal?: AbortSignal,
    overrideSearch: boolean = true
): Promise<{ text: string, sources?: any[] }> {
    
    const settings = { ...currentSettings };
    if (!overrideSearch) settings.enableSearch = false; // Disable search for simple tasks

    // 1. Zhipu / OpenAI / SiliconFlow Compatible
    if (settings.provider === 'zhipu' || settings.provider === 'openai' || settings.provider === 'siliconflow') {
        if (!settings.apiKey) throw new Error("API Key is required for third-party providers.");
        // Direct call without fallback logic (as requested to support Pro models correctly)
        return await runWithRetry(() => callOpenAICompatible(prompt, systemInstruction, isJsonMode, settings, signal), signal);
    }

    // 2. Gemini (Default) with Fallback Logic
    // We only use the fallback logic if the user hasn't strictly defined a custom model,
    // OR if the user is using the default 'gemini' provider without specific overrides.
    const models = [
        settings.model || 'gemini-2.0-flash', // Try user selection or default first
        'gemini-2.0-flash-lite-preview-02-05',
        'gemini-2.0-flash'
    ];
    // Remove duplicates
    const uniqueModels = [...new Set(models)];

    let lastError: any;

    for (const model of uniqueModels) {
        try {
            return await runWithRetry(() => callGemini(prompt, systemInstruction, isJsonMode, settings, signal, model), signal);
        } catch (error: any) {
            lastError = error;
            if (signal?.aborted) throw error;
            // Only continue to next model on 429/Quota/503
            const isQuota = error.message?.includes('429') || error.message?.includes('Quota') || error.message?.includes('Overloaded');
            if (!isQuota) throw error; // Fatal error
            console.warn(`Gemini model ${model} failed, trying next...`);
        }
    }

    throw lastError;
}


const SYSTEM_INSTRUCTION_ANALYSIS = `
Role: ä½ æ˜¯ä¸€ä½è®¡ç®—æœºé¢†åŸŸçš„èµ„æ·±ç§‘ç ”åŠ©æ‰‹ï¼Œæ“…é•¿å¿«é€Ÿè§£æå­¦æœ¯è®ºæ–‡å¹¶æå–æ ¸å¿ƒé€»è¾‘ã€‚
Task: è¯·å¸®æˆ‘æ£€ç´¢å¹¶é˜…è¯»æŒ‡å®šçš„è®¡ç®—æœºé¢†åŸŸæ–‡ç« /è¯é¢˜ã€‚ä½ çš„ç›®æ ‡æ˜¯ä¸ä»…æ€»ç»“åŸæ–‡ï¼Œè¿˜è¦ä»¥å®¡è¾©å¼æ€ç»´è¾…åŠ©æˆ‘è¿›è¡Œç§‘ç ”æ€è€ƒã€‚
Output Format: è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºMarkdownä»£ç å—æ ‡è®°ï¼ˆå¦‚ \`\`\`markdownï¼‰ï¼Œç›´æ¥è¾“å‡ºå†…å®¹ã€‚

ğŸ“„ è®ºæ–‡æ¦‚è§ˆ
æ ‡é¢˜: [æ–‡ç« æ ‡é¢˜]
ä½œè€…: [ä¸»è¦ä½œè€…å§“å]
å‘è¡¨å¹´ä»½/ä¼šè®®/æœŸåˆŠ: [ä¾‹å¦‚ï¼š2024 / IEEE INFOCOM]
é“¾æ¥: [arXiv/DOI é“¾æ¥]

ğŸ” æ ¸å¿ƒå†…å®¹
ç ”ç©¶é—®é¢˜: [é’ˆå¯¹ä»€ä¹ˆå…·ä½“çš„ç—›ç‚¹æˆ–æŒ‘æˆ˜ï¼Ÿï¼ˆç”¨ 1-2 å¥è¯æ¦‚æ‹¬ï¼‰]
ä¸»è¦æ–¹æ³•: [æå‡ºäº†ä»€ä¹ˆæ ·çš„ç®—æ³•ã€æ¶æ„æˆ–ç†è®ºè¯æ˜ï¼Ÿ]
å…³é”®è´¡çŒ®:
1. [è´¡çŒ® 1]
2. [è´¡çŒ® 2]
3. [è´¡çŒ® 3]

ğŸ’¡ å¯å‘ä¸æ€è€ƒ
äº®ç‚¹: [è®ºæ–‡æœ€ç²¾å¦™çš„è®¾è®¡æˆ–æœ€ä»¤äººä¿¡æœçš„å®éªŒç»“æœæ˜¯ä»€ä¹ˆï¼Ÿ]
ä¸è¶³: [å®éªŒè®¾ç½®ã€å‡è®¾å‰ææˆ–æ‰©å±•æ€§ä¸Šæ˜¯å¦å­˜åœ¨å±€é™æ€§ï¼Ÿ]
å¯å€Ÿé‰´ç‚¹: [å…¶ä¸­çš„å“ªäº›æŠ€æœ¯è·¯å¾„ã€è¯„ä¼°æŒ‡æ ‡æˆ–æ•°å­¦å·¥å…·å¯ä»¥è¿ç§»åˆ°å…¶ä»–ç ”ç©¶ä¸­ï¼Ÿè¯·ç»™å‡ºå…·ä½“ã€å¯æ“ä½œçš„è¿ç§»å»ºè®®ï¼Œå¹¶ç»“åˆæ½œåœ¨åº”ç”¨åœºæ™¯æä¾›ç¤ºä¾‹ã€‚]
å¾…è§£å†³é—®é¢˜: [è®ºæ–‡æåˆ°çš„æœªæ¥æ–¹å‘æˆ–ä½ è§‚å¯Ÿåˆ°çš„æœªç«Ÿä¹‹å¿—ã€‚]
å¤‡æ³¨: [ç»“åˆå½“å‰è®¡ç®—æœºé¢†åŸŸçš„æŠ€æœ¯è¶‹åŠ¿ï¼ˆå¦‚å¤§æ¨¡å‹ã€è¾¹ç¼˜è®¡ç®—ç­‰ï¼‰ç»™å‡ºæ·±åº¦çš„ä¸“ä¸šè¯„ä»·ã€‚]
`;

export const analyzePaperWithGemini = async (query: string, signal?: AbortSignal): Promise<AnalysisResult> => {
  const prompt = `Search for and analyze the paper related to: "${query}". If multiple papers match, choose the most relevant or influential one. Strictly follow the defined output format.`;
  
  try {
      const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_ANALYSIS, false, signal, true);
      return {
          markdown: result.text,
          groundingChunks: result.sources
      };
  } catch (error: any) {
      if (signal?.aborted || error.message === "Aborted") {
          throw new Error("Analysis process was stopped by the user.");
      }
      throw error;
  }
};

const SYSTEM_INSTRUCTION_GENERIC = "You are a helpful academic assistant.";

/**
 * Sub-agent to verify paper existence and find the official link.
 */
const verifyAndFindPaperLink = async (title: string, year: string): Promise<string | undefined> => {
    const prompt = `
      Task: Find the official URL for the specific paper: "${title}" (approx. year: ${year}).
      Output JSON only: { "found": boolean, "url": "string | null", "verified_title": "string" }
    `;

    try {
        const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, true, undefined, true);
        // Clean JSON (remove markdown blocks if present)
        const jsonStr = result.text.replace(/```json|```/g, '').trim();
        const data = JSON.parse(jsonStr);
        return data.found && data.url ? data.url : undefined;
    } catch (e) {
        return undefined;
    }
};

export const checkPaperTimeliness = async (title: string, authorAndYear: string): Promise<TimelinessReport> => {
    const prompt = `
        Role: Technical Research Auditor.
        Task: Analyze the timeliness of the paper "${title}" (${authorAndYear}).
        1. Determine if this paper is considered "Outdated" or "Legacy" (>3-5 years old in fast AI fields).
        2. Suggest 3 **State-of-the-Art (SOTA)** papers or direct successors.
        STRICT: At least ONE recommendation MUST be published in 2024-2025.
        
        Output JSON only:
        {
            "isOutdated": boolean,
            "status": "Legacy" | "Current" | "Seminal Classic",
            "summary": "Short explanation.",
            "recommendations": [ { "title": "Title", "year": "202X", "reason": "Reason" } ]
        }
    `;

    try {
        const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, true, undefined, true);
        const jsonStr = result.text.replace(/```json|```/g, '').trim();
        const report = JSON.parse(jsonStr) as TimelinessReport;

        // Phase 2: Verify links (Lazy logic: parallel execution, non-blocking for result return)
        if (report.recommendations && report.recommendations.length > 0) {
            verifyRecommendations(report.recommendations).then(verified => {
               // Note: This async update won't affect the immediate return, 
               // but in a real app we might update state. 
               // For now, we return the report immediately as verifying takes time.
            });
        }
        return report;
    } catch (e) {
        return { isOutdated: false, status: "Check Unavailable", summary: "Unable to verify timeliness.", recommendations: [] };
    }
};

async function verifyRecommendations(recs: any[]) {
    return Promise.all(recs.map(async (rec) => {
        const link = await verifyAndFindPaperLink(rec.title, rec.year);
        return { ...rec, link };
    }));
}

export const checkVenueQuality = async (venueText: string): Promise<VenueReport> => {
    const prompt = `
        Role: Academic Evaluator.
        Task: Analyze the academic reputation: "${venueText}".
        Output JSON only:
        {
            "name": "Canonical Name",
            "type": "Conference" | "Journal" | "Unknown",
            "quality": "Short Rating (e.g. 'CCF A')",
            "summary": "Concise summary."
        }
    `;

    try {
        const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, true, undefined, true);
        const jsonStr = result.text.replace(/```json|```/g, '').trim();
        return JSON.parse(jsonStr) as VenueReport;
    } catch (e) {
        return { name: venueText, type: 'Unknown', quality: 'Check Unavailable', summary: "Unable to analyze venue." };
    }
};

export const checkAuthorIntegrity = async (authors: string): Promise<IntegrityReport> => {
    const prompt = `
        Role: Academic Integrity Officer.
        Task: Check authors: "${authors}" for "academic misconduct", "retraction", "fraud".
        Rules: Be conservative. Only flag if verified.
        Output JSON only:
        {
            "hasIssues": boolean,
            "summary": "Concise findings."
        }
    `;

    try {
        const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, true, undefined, true);
        const jsonStr = result.text.replace(/```json|```/g, '').trim();
        return JSON.parse(jsonStr) as IntegrityReport;
    } catch (e) {
        return { hasIssues: false, summary: "Integrity check unavailable." };
    }
};

export const askFollowUp = async (
  question: string, 
  originalContext: string, 
  history: ChatMessage[]
): Promise<string> => {
  const historyContext = history.map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`).join('\n');

  const prompt = `
    Context (Original Analysis):
    ${originalContext}

    Conversation History:
    ${historyContext}

    Current User Question:
    ${question}

    INTERNAL INSTRUCTION:
    Critique your draft answer internally, then output ONLY the final answer inside <final_answer> tags.
    No markdown bolding (asterisks) in final answer.
  `;

  try {
    // Follow-up usually doesn't need web search unless specifically asked, but keeping it optional
    const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, false, undefined, false);
    
    const rawText = result.text;
    const match = rawText.match(/<final_answer>([\s\S]*?)<\/final_answer>/);
    
    if (match && match[1]) {
      return match[1].trim().replace(/\*\*/g, '');
    } else {
      return rawText.replace(/<final_answer>|<\/final_answer>/g, '').replace(/\*\*/g, '').trim();
    }
  } catch (error) {
    console.error("Follow-up Error:", error);
    throw error;
  }
};

export const analyzeTrendsWithGemini = async (history: HistoryItem[]): Promise<string> => {
  if (history.length === 0) return "No history available.";

  let aggregatedContext = "";
  history.forEach((item, index) => {
    aggregatedContext += `\n--- PAPER ${index + 1} ---\nTitle: ${item.title}\nAnalysis: ${item.analysis.markdown}\n`;
  });

  const prompt = `
    Role: Chief Research Scientist.
    Task: Generate a Trend & Evolution Report based on these papers:
    ${aggregatedContext}
    
    Output Markdown:
    # ğŸ“ˆ é¢†åŸŸæ¼”è¿›ä¸è¶‹åŠ¿æ·±åº¦åˆ†ææŠ¥å‘Š
    (Sections: Chronological Order, Field Evolution, Technical Flows, Future Directions, Recommended Reading)
  `;

  try {
    const result = await dispatchAIRequest(prompt, SYSTEM_INSTRUCTION_GENERIC, false, undefined, true);
    return result.text;
  } catch (error) {
    throw error;
  }
};
