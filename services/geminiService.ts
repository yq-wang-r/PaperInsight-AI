import { GoogleGenAI, Tool, Part } from "@google/genai";
import { AnalysisResult, ChatMessage, HistoryItem, TimelinessReport, IntegrityReport, VenueReport } from "../types";

const SYSTEM_INSTRUCTION = `
Role: ‰Ω†ÊòØ‰∏Ä‰ΩçËÆ°ÁÆóÊú∫È¢ÜÂüüÁöÑËµÑÊ∑±ÁßëÁ†îÂä©ÊâãÔºåÊìÖÈïøÂø´ÈÄüËß£ÊûêÂ≠¶ÊúØËÆ∫ÊñáÂπ∂ÊèêÂèñÊ†∏ÂøÉÈÄªËæë„ÄÇ
Task: ËØ∑Â∏ÆÊàëÊ£ÄÁ¥¢Âπ∂ÈòÖËØªÊåáÂÆöÁöÑËÆ°ÁÆóÊú∫È¢ÜÂüüÊñáÁ´†/ËØùÈ¢ò„ÄÇ‰Ω†ÁöÑÁõÆÊ†áÊòØ‰∏ç‰ªÖÊÄªÁªìÂéüÊñáÔºåËøòË¶Å‰ª•ÂÆ°Ëæ©ÂºèÊÄùÁª¥ËæÖÂä©ÊàëËøõË°åÁßëÁ†îÊÄùËÄÉ„ÄÇ
Language Requirement: ËØ∑‰∏ªË¶Å‰ΩøÁî®**‰∏≠Êñá**ËøõË°åËß£ËØªÂíåÊÄªÁªì„ÄÇÂØπ‰∫é**Êï∞Â≠¶Á¨¶Âè∑„ÄÅ‰∏ì‰∏öÊúØËØ≠„ÄÅ‰∏ìÊúâÂêçËØç„ÄÅÁÆóÊ≥ïÂêçÁß∞**ÔºàÂ¶Ç Transformer, Attention Mechanism, ResNet, Zero-shot Learning, NP-hard Á≠âÔºâÔºåËØ∑Âä°ÂøÖ**‰øùÁïôËã±ÊñáÂéüÊñá**Ôºå‰∏çË¶ÅÂº∫Ë°åÁøªËØë„ÄÇ**ÂêåÊó∂Ôºå‰∏∫‰∫Ü‰æø‰∫éÁêÜËß£ÔºåËØ∑Âú®Ëøô‰∫õËã±ÊñáÊúØËØ≠Âá∫Áé∞Êó∂ÔºåÂ∞ùËØïÁî®‰∏≠ÊñáËøõË°åÁÆÄÂçïÁöÑËß£ÈáäÊàñË°•ÂÖÖËØ¥Êòé„ÄÇ**
Output Format: ËØ∑‰∏•Ê†ºÊåâÁÖß‰ª•‰∏ã Markdown Ê†ºÂºèËæìÂá∫Ôºå‰∏çË¶ÅËæìÂá∫Markdown‰ª£Á†ÅÂùóÊ†áËÆ∞ÔºàÂ¶Ç \`\`\`markdownÔºâÔºåÁõ¥Êé•ËæìÂá∫ÂÜÖÂÆπ„ÄÇ

üìÑ ËÆ∫ÊñáÊ¶ÇËßà
Ê†áÈ¢ò: [ÊñáÁ´†Ê†áÈ¢ò]
‰ΩúËÄÖ: [‰∏ªË¶Å‰ΩúËÄÖÂßìÂêç]
ÂèëË°®Âπ¥‰ªΩ/‰ºöËÆÆ/ÊúüÂàä: [‰æãÂ¶ÇÔºö2024 / IEEE INFOCOM]
ÈìæÊé•: [arXiv/DOI ÈìæÊé•]

üîç Ê†∏ÂøÉÂÜÖÂÆπ
Á†îÁ©∂ÈóÆÈ¢ò: [ÈíàÂØπ‰ªÄ‰πàÂÖ∑‰ΩìÁöÑÁóõÁÇπÊàñÊåëÊàòÔºüÔºàÁî® 1-2 Âè•ËØùÊ¶ÇÊã¨Ôºâ]
‰∏ªË¶ÅÊñπÊ≥ï: [ÊèêÂá∫‰∫Ü‰ªÄ‰πàÊ†∑ÁöÑÁÆóÊ≥ï„ÄÅÊû∂ÊûÑÊàñÁêÜËÆ∫ËØÅÊòéÔºü‰øùÁïôÊ†∏ÂøÉËã±ÊñáÊúØËØ≠Âπ∂ËøõË°åÁÆÄÂçïËß£Èáä]
ÂÖ≥ÈîÆË¥°ÁåÆ:
1. [Ë¥°ÁåÆ 1]
2. [Ë¥°ÁåÆ 2]
3. [Ë¥°ÁåÆ 3]

üí° ÂêØÂèë‰∏éÊÄùËÄÉ
‰∫ÆÁÇπ: [ËÆ∫ÊñáÊúÄÁ≤æÂ¶ôÁöÑËÆæËÆ°ÊàñÊúÄ‰ª§‰∫∫‰ø°ÊúçÁöÑÂÆûÈ™åÁªìÊûúÊòØ‰ªÄ‰πàÔºü]
‰∏çË∂≥: [ÂÆûÈ™åËÆæÁΩÆ„ÄÅÂÅáËÆæÂâçÊèêÊàñÊâ©Â±ïÊÄß‰∏äÊòØÂê¶Â≠òÂú®Â±ÄÈôêÊÄßÔºü]
ÂèØÂÄüÈâ¥ÁÇπ: [ÂÖ∂‰∏≠ÁöÑÂì™‰∫õÊäÄÊúØË∑ØÂæÑ„ÄÅËØÑ‰º∞ÊåáÊ†áÊàñÊï∞Â≠¶Â∑•ÂÖ∑ÂèØ‰ª•ËøÅÁßªÂà∞ÂÖ∂‰ªñÁ†îÁ©∂‰∏≠ÔºüËØ∑ÁªôÂá∫ÂÖ∑‰Ωì„ÄÅÂèØÊìç‰ΩúÁöÑËøÅÁßªÂª∫ËÆÆÔºåÂπ∂ÁªìÂêàÊΩúÂú®Â∫îÁî®Âú∫ÊôØÊèê‰æõÁ§∫‰æã„ÄÇ]
ÂæÖËß£ÂÜ≥ÈóÆÈ¢ò: [ËÆ∫ÊñáÊèêÂà∞ÁöÑÊú™Êù•ÊñπÂêëÊàñ‰Ω†ËßÇÂØüÂà∞ÁöÑÊú™Á´ü‰πãÂøó„ÄÇ]
Â§áÊ≥®: [ÁªìÂêàÂΩìÂâçËÆ°ÁÆóÊú∫È¢ÜÂüüÁöÑÊäÄÊúØË∂ãÂäøÔºàÂ¶Ç LLM, Edge AI Á≠âÔºâÁªôÂá∫Ê∑±Â∫¶ÁöÑ‰∏ì‰∏öËØÑ‰ª∑„ÄÇ]
`;

/**
 * Robustly extracts the JSON object from a string.
 * Handles cases where the model outputs multiple JSON blocks (e.g. thoughts + result)
 * or includes markdown formatting.
 */
const extractJSON = (text: string): any => {
  if (!text) return null;

  // 1. Try cleaning markdown and parsing directly
  const cleanText = text.replace(/^```json\s*/i, '').replace(/^```\s*/, '').replace(/\s*```$/, '').trim();
  try {
      return JSON.parse(cleanText);
  } catch (e) {
      // Continue if simple parse fails
  }

  // 2. Stack-based extractor to find all top-level JSON objects
  // This handles cases like: { "thought": ... } { "answer": ... }
  const candidates: any[] = [];
  let depth = 0;
  let start = -1;
  let insideString = false;
  let escape = false;

  for (let i = 0; i < text.length; i++) {
      const char = text[i];
      
      if (escape) {
          escape = false;
          continue;
      }
      if (char === '\\') {
          escape = true;
          continue;
      }
      if (char === '"') {
          insideString = !insideString;
          continue;
      }
      
      if (!insideString) {
          if (char === '{') {
              if (depth === 0) start = i;
              depth++;
          } else if (char === '}') {
              depth--;
              if (depth === 0 && start !== -1) {
                  const chunk = text.substring(start, i + 1);
                  try {
                      const parsed = JSON.parse(chunk);
                      candidates.push(parsed);
                  } catch (e) {
                      // ignore invalid chunks
                  }
                  start = -1;
              }
          }
      }
  }

  if (candidates.length > 0) {
      // Return the last valid JSON object found, as it's typically the final response
      return candidates[candidates.length - 1];
  }

  // 3. Last resort: Find first '{' and last '}'
  const firstOpen = text.indexOf('{');
  const lastClose = text.lastIndexOf('}');
  if (firstOpen !== -1 && lastClose !== -1 && lastClose > firstOpen) {
      try {
          return JSON.parse(text.substring(firstOpen, lastClose + 1));
      } catch (e) {
          return null;
      }
  }

  return null;
};

export const analyzePaperWithGemini = async (
    query: string, 
    signal?: AbortSignal, 
    pdfBase64?: string, 
    enableSearch: boolean = true
): Promise<AnalysisResult> => {
  if (!process.env.API_KEY) {
    throw new Error("API Key is missing. Please set it in the environment.");
  }

  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  // Configure tools based on enableSearch flag
  const tools: Tool[] = enableSearch ? [{ googleSearch: {} }] : [];
  
  // Construct content parts
  const parts: Part[] = [];

  if (pdfBase64) {
      // PDF Mode: Add the PDF data
      parts.push({
          inlineData: {
              mimeType: 'application/pdf',
              data: pdfBase64
          }
      });
      // Add a prompt to analyze the attached file
      const userPrompt = query.trim() 
          ? `Please analyze this uploaded paper. Focus on this context: "${query}". Strictly follow the defined output format and language rules (Chinese with English terms).` 
          : `Please analyze this uploaded paper. Strictly follow the defined output format and language rules (Chinese with English terms).`;
      parts.push({ text: userPrompt });
  } else {
      // Search Mode: Standard text prompt
      parts.push({ text: `Search for and analyze the paper related to: "${query}". If multiple papers match, choose the most relevant or influential one. Strictly follow the defined output format and language rules (Chinese with English terms).` });
  }

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.0-flash', // Using 2.0 Flash for efficiency with PDFs
      contents: { parts },
      config: {
        systemInstruction: SYSTEM_INSTRUCTION,
        tools: tools, // Only include search tool if enabled
        temperature: 0.3, 
      }
    });

    // Check for abort after the async operation
    if (signal?.aborted) {
        throw new Error("Aborted");
    }

    const text = response.text || "Analysis generation failed.";
    const groundingChunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks as any[];

    return {
      markdown: text,
      groundingChunks: groundingChunks
    };
  } catch (error: any) {
    if (signal?.aborted || error.message === "Aborted") {
        throw new Error("Analysis process was stopped by the user.");
    }
    console.error("Gemini API Error:", error);
    throw error;
  }
};

/**
 * Sub-agent to verify paper existence and find the official link.
 */
const verifyAndFindPaperLink = async (title: string, year: string): Promise<string | undefined> => {
    if (!process.env.API_KEY) return undefined;
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    // Strict prompt to ensure "Sub-agent" behavior
    const prompt = `
      Role: Academic Librarian.
      Task: Find the official URL for the specific paper: "${title}" (approx. year: ${year}).
      
      Steps:
      1. Search Google for this exact paper title.
      2. Verify the search result is indeed for the paper "${title}".
      3. If found, provide the direct link (e.g. arXiv, IEEE Xplore, ACM Digital Library, CVF, etc.).
      4. If the paper cannot be found or the results are for a different paper, return null.

      Output JSON only: 
      { 
        "found": boolean, 
        "url": "string | null", 
        "verified_title": "string" 
      }
    `;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.0-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                tools: [{ googleSearch: {} }],
                temperature: 0.1 // Very low temp for strict fact checking
            }
        });
        
        const result = extractJSON(response.text || "{}");
        if (result && result.found && result.url) {
            return result.url;
        }
        return undefined;
    } catch (e) {
        console.error(`Failed to verify link for ${title}`, e);
        return undefined;
    }
};

export const checkPaperTimeliness = async (title: string, authorAndYear: string): Promise<TimelinessReport> => {
    if (!process.env.API_KEY) throw new Error("API Key missing");
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    // Enforce "Latest" paper requirement in prompt
    const prompt = `
        Role: Technical Research Auditor.
        Task: Analyze the timeliness of the paper "${title}" (${authorAndYear}).
        1. Determine if this paper is considered "Outdated" or "Legacy" (typically >3-5 years old in fast-moving CS fields like AI, or if superseded by newer architectures).
        2. Suggest 3 **State-of-the-Art (SOTA)** papers or direct successors.
        
        STRICT REQUIREMENT:
        - At least ONE recommendation MUST be published in the current year (2024-2025). This is MANDATORY. Search for the very latest preprints if necessary.
        - The other recommendations can be seminal papers from the last 1-3 years.
        - **Output the summary in Chinese.**
        - Do not format the JSON with Markdown.
        
        Output JSON only:
        {
            "isOutdated": boolean,
            "status": "Legacy" | "Current" | "Seminal Classic",
            "summary": "Short explanation (max 1 sentence) on why it is/isn't outdated (in Chinese).",
            "recommendations": [
                { "title": "Paper Title", "year": "202X", "reason": "Why it's better (in Chinese)" }
            ]
        }
    `;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.0-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                tools: [{ googleSearch: {} }], 
                temperature: 0.2
            }
        });
        
        const report = extractJSON(response.text || "{}") as TimelinessReport;
        
        if (!report) {
             throw new Error("Failed to parse Timeliness JSON");
        }

        // Phase 2: Sub-agent verification loop
        if (report.recommendations && report.recommendations.length > 0) {
            const verifiedRecommendations = await Promise.all(
                report.recommendations.map(async (rec) => {
                    const verifiedLink = await verifyAndFindPaperLink(rec.title, rec.year);
                    return {
                        ...rec,
                        link: verifiedLink
                    };
                })
            );
            report.recommendations = verifiedRecommendations;
        }

        return report;

    } catch (e) {
        console.error("Timeliness check failed", e);
        return { isOutdated: false, status: "Unknown", summary: "Could not verify timeliness.", recommendations: [] };
    }
};

export const checkVenueQuality = async (venueText: string): Promise<VenueReport> => {
    if (!process.env.API_KEY) throw new Error("API Key missing");
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    const prompt = `
        Role: Academic Evaluator.
        Task: Analyze the academic reputation and quality of this publication venue: "${venueText}".
        
        Instructions:
        1. Identify the canonical name (e.g., "CVPR" for "Conf. on Computer Vision...").
        2. Rate its quality/tier. Focus on "Reputation" and "Word of Mouth" (Âè£Á¢ë).
           - e.g., "Top-tier conference, highly respected", "CCF A", "Q1 Journal".
        3. Provide a concise summary (1-2 sentences) about its community standing and review rigor.
        
        Language: Output summary in Chinese.

        Output JSON only:
        {
            "name": "Canonical Name",
            "type": "Conference" | "Journal" | "Unknown",
            "quality": "Short Rating (e.g. 'CCF A / Top Tier')",
            "summary": "Concise summary of reputation (in Chinese)."
        }
    `;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.0-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                tools: [{ googleSearch: {} }],
                temperature: 0.1
            }
        });
        
        const report = extractJSON(response.text || "{}");
        return report || { name: venueText, type: 'Unknown', quality: 'Unknown', summary: "Could not analyze venue." };
    } catch (e) {
        return { name: venueText, type: 'Unknown', quality: 'Unknown', summary: "Could not analyze venue." };
    }
};

export const checkAuthorIntegrity = async (authors: string): Promise<IntegrityReport> => {
    if (!process.env.API_KEY) throw new Error("API Key missing");
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    const prompt = `
        Role: Academic Integrity Officer.
        Task: Perform a background check on these authors/institutions: "${authors}".
        Search specifically for: "academic misconduct", "paper retraction", "data fabrication", "fraud".
        
        Rules:
        - Be conservative. Only flag if there are *verified* public records of misconduct.
        - If clear, state "No public records of academic misconduct found."
        - Keep it very concise.
        - Output summary in Chinese.
        
        Output JSON only:
        {
            "hasIssues": boolean,
            "summary": "Concise findings (in Chinese)."
        }
    `;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.0-flash',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                tools: [{ googleSearch: {} }],
                temperature: 0.1
            }
        });
        
        const report = extractJSON(response.text || "{}");
        return report || { hasIssues: false, summary: "Integrity check unavailable." };
    } catch (e) {
        return { hasIssues: false, summary: "Integrity check unavailable." };
    }
};

export const askFollowUp = async (
  question: string, 
  originalContext: string, 
  history: ChatMessage[]
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API Key is missing.");
  }

  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  // Construct context from history
  const historyContext = history.map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`).join('\n');

  const prompt = `
    Context (Original Analysis):
    ${originalContext}

    Conversation History:
    ${historyContext}

    Current User Question:
    ${question}

    INTERNAL INSTRUCTION (CRITICAL):
    You must perform an internal critique before answering. 
    1. Draft an initial answer based on the paper analysis and your knowledge.
    2. Critique your draft: Does it directly address the user's specific question? Is the tone professional and academic? Is it accurate?
    3. Refine the answer based on the critique.
    4. **Language Rule**: Answer primarily in Chinese. Keep technical terms in English.
    5. **IMPORTANT**: Do not use Markdown bolding (i.e., do not use **asterisks**) in the final answer. Keep it plain text for easier reading.
    
    OUTPUT FORMAT:
    You must wrap your FINAL, polished answer inside <final_answer> tags. Do not show the critique process to the user, only the result inside the tags.
    
    Example:
    <final_answer>
    ËøôÁØáÊñáÁ´†‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Âü∫‰∫é Transformer ÁöÑÊû∂ÊûÑ...
    </final_answer>
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.0-flash', // Flash is sufficient for chat context
      contents: prompt,
      config: {
        temperature: 0.5,
      }
    });

    const rawText = response.text || "";
    
    // Extract content within <final_answer> tags and clean up markdown bolding
    const match = rawText.match(/<final_answer>([\s\S]*?)<\/final_answer>/);
    
    if (match && match[1]) {
      return match[1].trim().replace(/\*\*/g, '');
    } else {
      // Fallback if model fails to tag (rare with high temp, but possible)
      return rawText.replace(/<final_answer>|<\/final_answer>/g, '').replace(/\*\*/g, '').trim();
    }

  } catch (error) {
    console.error("Follow-up Error:", error);
    throw error;
  }
};

export const analyzeTrendsWithGemini = async (history: HistoryItem[]): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API Key is missing.");
  }

  if (history.length === 0) {
     return "No history available to analyze.";
  }

  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  // Prepare the context from history
  let aggregatedContext = "";
  
  history.forEach((item, index) => {
    aggregatedContext += `
    --- PAPER ${index + 1} ---
    Title: ${item.title}
    Analysis Content (Excerpt):
    ${item.analysis.markdown.substring(0, 1500)}...
    -------------------------
    `;
  });

  const prompt = `
    Role: Domain Expert & Research Director.
    
    Task: You are reviewing a collection of paper analyses. Your goal is to generate a **Domain-Specific Trend Report**.
    
    Input Data:
    ${aggregatedContext}

    CRITICAL INSTRUCTIONS:
    1. **Cluster by Domain**: First, identify if the papers belong to different domains (e.g., "Computer Vision", "LLMs", "Distributed Systems"). 
       - Do NOT force connections between unrelated papers.
       - If the papers are totally distinct (e.g., one on Biology, one on Crypto), analyze them as separate clusters.
    2. **Intelligent Synthesis**:
       - Within each domain cluster, analyze the chronological evolution and technical shifts.
       - Only mention cross-domain connections if they are genuinely meaningful.
    3. **Language**: Use **Chinese** for the report text, but keep technical terms (e.g. RAG, Diffusion Models) in **English**.

    Output Format (Markdown):
    
    # üß¨ ÁßëÁ†îË∂ãÂäøÁªºÂêàÁ†îÂà§ (Comprehensive Research Trend Report)

    [If multiple domains are detected, add a brief intro: "Êú¨Ê¨°ÂàÜÊûêÊ∂µÁõñ‰∫Ü‰ª•‰∏ãÂá†‰∏™Áã¨Á´ã/‰∫§ÂèâÈ¢ÜÂüü: [Domain A], [Domain B]..."]

    ## 1. üîç È¢ÜÂüüÂàÜÁ±ª‰∏éËÅöÁ±ª (Domain Clustering)
    (Briefly list the clusters identified. e.g., "Cluster A: Efficient LLM Inference", "Cluster B: Graph Neural Networks")

    ## 2. ‚è≥ Ê†∏ÂøÉÈ¢ÜÂüüÊ∑±Â∫¶ÂâñÊûê (Deep Dive per Domain)
    
    ### 2.1 [Domain Name A]
    - **ÊºîËøõËÑâÁªú**: (How this specific field evolved based on the papers provided)
    - **ÊäÄÊúØÊãêÁÇπ**: (Key architectural shifts)
    - **ÂΩìÂâçSOTA**: (Current state based on these papers)

    ### 2.2 [Domain Name B] (If applicable)
    ...

    ## 3. üí° Ë∑®È¢ÜÂüüÂêØÂèë‰∏éÁõ≤ÁÇπ (Cross-Domain Insights & Gaps)
    - (Only if valid) "Intersection points..."
    - **Research Gaps**: (What is missing in the current set of papers?)

    ## 4. üöÄ Âª∫ËÆÆÊé¢Á¥¢ÊñπÂêë (Future Directions)
    (Concrete, actionable research ideas for the user)
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview', 
      contents: prompt,
      config: {
        temperature: 0.3,
        tools: [{ googleSearch: {} }],
      }
    });

    return response.text || "Failed to generate trend report.";

  } catch (error) {
    console.error("Trend Analysis Error:", error);
    throw error;
  }
};